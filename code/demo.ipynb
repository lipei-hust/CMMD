{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "n = 1000\n",
    "Q = 3\n",
    "P = 2\n",
    "heads = 8\n",
    "embedding_dimension = 8\n",
    "lr = 5e-4\n",
    "nodes = 8\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "X = torch.randn(n, nodes, Q).to(device)\n",
    "Y = torch.randn(n, P).to(device)\n",
    "u1 = torch.tensor([0,1,2,3,\n",
    "                    4,5,6,7,\n",
    "                    0,4,\n",
    "                    1,5,\n",
    "                    2,6,\n",
    "                    3,7])\n",
    "v1 = torch.tensor([0,0,0,0,\n",
    "              5,5,5,5,\n",
    "              4,4,\n",
    "              1,1,\n",
    "              2,2,\n",
    "              3,3])\n",
    "g1 = dgl.graph((u1,v1)).to(device)\n",
    "\n",
    "u2 = torch.tensor([0,1,2,3,4,5])\n",
    "v2 = torch.tensor([6,6,6,6,6,6])\n",
    "g2 = dgl.graph((u2,v2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats,out_feats):\n",
    "        super().__init__()\n",
    "        # 实例化SAGEConve，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregator_type是聚合函数的类型\n",
    "        self.conv1 = dglnn.GATConv(\n",
    "            in_feats=in_feats, out_feats=hidden_feats,num_heads = heads, allow_zero_in_degree=True)\n",
    "        self.conv2 = dglnn.GATConv(\n",
    "            in_feats=hidden_feats, out_feats=hidden_feats, num_heads = heads, allow_zero_in_degree=True)\n",
    "        self.mlp = torch.nn.Linear(hidden_feats, out_feats)\n",
    "\n",
    "    def forward(self, graph1, graph2, inputs):\n",
    "        # 输入是节点的特征\n",
    "        h = self.conv1(graph1, inputs)\n",
    "        h = torch.sum(h,1)\n",
    "        h = h[:6]\n",
    "        h = torch.vstack((h,torch.zeros(1,h.shape[-1]).to(device)))\n",
    "        h = self.conv2(graph2,h)\n",
    "        h = torch.sum(h,1)\n",
    "        h = h[-1]\n",
    "        h = self.mlp(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(X,Y):\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        yield X[i],Y[i]\n",
    "        i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14518514275550842\n",
      "0.12449261546134949\n",
      "0.1055426150560379\n",
      "0.08828239887952805\n",
      "0.07270374894142151\n",
      "0.05878599360585213\n",
      "0.04650646448135376\n",
      "0.03584323823451996\n",
      "0.026740631088614464\n",
      "0.019135532900691032\n",
      "0.012960558757185936\n",
      "0.008133267052471638\n",
      "0.0045553757809102535\n",
      "0.002111895941197872\n",
      "0.0006593635771423578\n",
      "4.668055407819338e-05\n",
      "0.0001091367521439679\n",
      "0.0006737431976944208\n",
      "0.0015665313694626093\n",
      "0.002621683292090893\n",
      "0.00369146722368896\n",
      "0.004654976073652506\n",
      "0.005423668771982193\n",
      "0.005942920222878456\n",
      "0.006190318148583174\n",
      "0.006171228364109993\n",
      "0.0059128799475729465\n",
      "0.005457884632050991\n",
      "0.004857689142227173\n",
      "0.0041667805053293705\n",
      "0.003437851322814822\n",
      "0.00271802581846714\n",
      "0.002046378096565604\n",
      "0.00145246391184628\n",
      "0.0009558270103298128\n",
      "0.0005663233459927142\n",
      "0.00028511430718936026\n",
      "0.00010596645734040067\n",
      "1.6996766134980135e-05\n",
      "2.444196297801682e-06\n",
      "4.4421871280064806e-05\n",
      "0.00012453441740944982\n",
      "0.00022524964879266918\n",
      "0.0003309870953671634\n",
      "0.0004288750351406634\n",
      "0.0005091900820843875\n",
      "0.0005655313143506646\n",
      "0.0005946964956820011\n",
      "0.0005964057054370642\n",
      "0.0005727937095798552\n",
      "0.0005278674070723355\n",
      "0.0004668651381507516\n",
      "0.000395631737774238\n",
      "0.00032006853143684566\n",
      "0.0002456289657857269\n",
      "0.000176955945789814\n",
      "0.00011759812332456931\n",
      "6.988332461332902e-05\n",
      "3.4887056244770065e-05\n",
      "1.252041147381533e-05\n",
      "1.6989137066047988e-06\n",
      "5.818552608616301e-07\n",
      "6.840037258371012e-06\n",
      "1.7931341062649153e-05\n",
      "3.135285805910826e-05\n",
      "4.4858112232759595e-05\n",
      "5.662316470989026e-05\n",
      "6.533896521432325e-05\n",
      "7.025329250609502e-05\n",
      "7.115473272278905e-05\n",
      "6.829229096183553e-05\n",
      "6.227756239240989e-05\n",
      "5.3957788622938097e-05\n",
      "4.4294956751400605e-05\n",
      "3.424729220569134e-05\n",
      "2.4669758204254322e-05\n",
      "1.6246591258095577e-05\n",
      "9.444516763323918e-06\n",
      "4.503415311774006e-06\n",
      "1.446220721845748e-06\n",
      "1.1358603302369374e-07\n",
      "2.092229465233686e-07\n",
      "1.351982177766331e-06\n",
      "3.1282752388506196e-06\n",
      "5.140440407558344e-06\n",
      "7.043639925541356e-06\n",
      "8.574088496970944e-06\n",
      "9.560603757563513e-06\n",
      "9.927520295605063e-06\n",
      "9.686154044175055e-06\n",
      "8.917279046727344e-06\n",
      "7.750633812975138e-06\n",
      "6.342581400531344e-06\n",
      "4.85240980196977e-06\n",
      "3.4266522561665624e-06\n",
      "2.181663376177312e-06\n",
      "1.1958017012148048e-06\n",
      "5.082458756078267e-07\n",
      "1.201994734856271e-07\n",
      "2.04775085776987e-11\n"
     ]
    }
   ],
   "source": [
    "model = GAT(in_feats=Q, hidden_feats=embedding_dimension,out_feats=P).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    for x, y in data_iter(X,Y):\n",
    "        # print(x)\n",
    "        # 使用所有节点(全图)进行前向传播计算\n",
    "        logits = model(g1, g2, x)\n",
    "        # 计算损失值\n",
    "        l = loss(input=logits, target=y)\n",
    "        # # 进行反向传播计算\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        print(l.item())\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
